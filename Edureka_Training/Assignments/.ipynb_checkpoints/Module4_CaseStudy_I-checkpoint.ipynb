{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0681edb5",
   "metadata": {},
   "source": [
    "# 1. Extract data from the given SalaryGender CSV file and store the data from each column in a separate NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e4ef1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "43f7d77a",
   "metadata": {},
   "source": [
    "# 2. Find: 1. The number of men with a PhD 2. The number of women with a PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15d5655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8b1f0d9e",
   "metadata": {},
   "source": [
    "# 3. Use SalaryGender CSV file. Store the “Age” and “PhD” columns in one DataFrame and delete the data of all people who don’t have a PhD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1148eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d25590a5",
   "metadata": {},
   "source": [
    "# 4. Calculate the total number of people who have a PhD degree from SalaryGender CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d4d719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa8e1ef2",
   "metadata": {},
   "source": [
    "# 5. How do you Count The Number Of Times Each Value Appears In An Array Of Integers?\n",
    "    [0, 5, 4, 0, 4, 4, 3, 0, 0, 5, 2, 1, 1, 9]\n",
    "    Answer should be array([4, 2, 1, 1, 3, 2, 0, 0, 0, 1]) which means 0 comes 4 times, 1 comes 2 times, 2 comes 1 time, 3 comes 1 time and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ca383d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d40270b",
   "metadata": {},
   "source": [
    "# 6. Create a numpy array [[0, 1, 2], [ 3, 4, 5], [ 6, 7, 8],[ 9, 10, 11]]) and filter the elements greater than 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "398e306d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1b9f3c38",
   "metadata": {},
   "source": [
    "# 7. Create a numpy array having NaN (Not a Number) and print it.\n",
    "    array([ nan, 1., 2., nan, 3., 4., 5.])\n",
    "    Print the same array omitting all elements which are nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc777747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6bca5dd0",
   "metadata": {},
   "source": [
    "# 8. Create a 10x10 array with random values and find the minimum and maximum values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cc94a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "11fa6b99",
   "metadata": {},
   "source": [
    "# 9. Create a random vector of size 30 and find the mean value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b2d126",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9390676e",
   "metadata": {},
   "source": [
    "# 10. Create numpy array having elements 0 to 10 And negate all the elements between 3 and 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a7cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "94a89949",
   "metadata": {},
   "source": [
    "# 11. Create a random array of 3 rows and 3 columns and sort it according to 1st column, 2nd column or 3rd column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a610e383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f2c9e0c",
   "metadata": {},
   "source": [
    "# 12. Create a four dimensions array get sum over the last two axis at once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49ffccc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "57415e11",
   "metadata": {},
   "source": [
    "# 13. Create a random array and swap two rows of an array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e0773d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4030805",
   "metadata": {},
   "source": [
    "# 14. Create a random matrix and Compute a matrix rank."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390b330d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77229dee",
   "metadata": {},
   "source": [
    "# 15. Analyse various school outcomes in Tennessee using pandas. Suppose you are a public school administrator. Some schools in your state of Tennessee are performing below average academically. Your superintendent, under pressure from frustrated parents and voters, approached you with the task of understanding why these schools are under-performing. To improve school performance, you need to learn more about these schools and their students, just as a business needs to understand its own strengths and weaknesses and its customers. Though you is eager to build an impressive explanatory model, you know the importance of conducting preliminary research to prevent possible pitfalls or blind spots. Thus, you engages in a thorough exploratory analysis, which includes: a lit review, data collection, descriptive and inferential statistics, and data visualization.\n",
    "    Phase 1 - Data Collection\n",
    "    Here is a data of every public school in middle Tennessee. The data also includes various demographic, school faculty, and income variables. You need to convert the data into useful information.\n",
    "    • Read the data in pandas data frame\n",
    "    • Describe the data to find more details\n",
    "    Phase 2 - Group data by school ratings\n",
    "    Chooses indicators that describe the student body (for example, reduced_lunch) or school administration (stu_teach_ratio) hoping they will explain school_rating. reduced_lunch is a variable measuring the average percentage of students per school enrolled in a federal program that provides lunches for students from lower-income households. In short, reduced_lunch is a good proxy for household income.\n",
    "    Isolates ‘reduced_lunch’ and groups the data by ‘school_rating’ using pandas groupby method and then uses describe on the re-shaped data\n",
    "    Phase 3 – Correlation analysis\n",
    "    Find the correlation between ‘reduced_lunch’ and ‘school_rating’. The values in the correlation matrix table will be between -1 and 1. A value of -1 indicates the strongest possible negative correlation, meaning as one variable decreases the other increases. And a value of 1 indicates the opposite.\n",
    "    Phase 4 – Scatter Plot\n",
    "    Find the relationship between school_rating and reduced_lunch, Plot a graph with the two variables on a scatter plot. Each dot represents a school. The placement of the dot represents that school's rating (Y-axis) and the percentage of its students on reduced lunch (x-axis). The downward trend line shows the negative correlation between school_rating and reduced_lunch (as one increases, the other decreases). The slope of the trend line indicates how much school_rating decreases as reduced_lunch increases. A steeper slope would indicate that a small change in reduced_lunch has a big impact on school_rating while a more horizontal slope would indicate that the same small change in reduced_lunch has a smaller impact on school_rating.\n",
    "    Phase 5 – Correlation Matrix\n",
    "    An efficient graph for assessing relationships is the correlation matrix, as seen below; its color-coded cells make it easier to interpret than the tabular correlation matrix above. Red cells indicate positive correlation; blue cells indicate negative correlation; white cells indicate no correlation. The darker the colors, the stronger the correlation (positive or negative) between those two variables. Draw a graph of correlation matrix having all important fields of data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6178642",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
