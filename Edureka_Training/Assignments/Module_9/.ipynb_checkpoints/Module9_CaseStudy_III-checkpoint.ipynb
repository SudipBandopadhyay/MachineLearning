{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "399a230e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV,RepeatedKFold\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6aef9",
   "metadata": {},
   "source": [
    "1. Load the data from “college.csv” that has attributes collected about private and public colleges for a particular year. We will try to predict the private/public status of the college from other attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48386ee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Private</th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1660</td>\n",
       "      <td>1232</td>\n",
       "      <td>721</td>\n",
       "      <td>23</td>\n",
       "      <td>52</td>\n",
       "      <td>2885</td>\n",
       "      <td>537</td>\n",
       "      <td>7440</td>\n",
       "      <td>3300</td>\n",
       "      <td>450</td>\n",
       "      <td>2200</td>\n",
       "      <td>70</td>\n",
       "      <td>78</td>\n",
       "      <td>18.1</td>\n",
       "      <td>12</td>\n",
       "      <td>7041</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>2186</td>\n",
       "      <td>1924</td>\n",
       "      <td>512</td>\n",
       "      <td>16</td>\n",
       "      <td>29</td>\n",
       "      <td>2683</td>\n",
       "      <td>1227</td>\n",
       "      <td>12280</td>\n",
       "      <td>6450</td>\n",
       "      <td>750</td>\n",
       "      <td>1500</td>\n",
       "      <td>29</td>\n",
       "      <td>30</td>\n",
       "      <td>12.2</td>\n",
       "      <td>16</td>\n",
       "      <td>10527</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yes</td>\n",
       "      <td>1428</td>\n",
       "      <td>1097</td>\n",
       "      <td>336</td>\n",
       "      <td>22</td>\n",
       "      <td>50</td>\n",
       "      <td>1036</td>\n",
       "      <td>99</td>\n",
       "      <td>11250</td>\n",
       "      <td>3750</td>\n",
       "      <td>400</td>\n",
       "      <td>1165</td>\n",
       "      <td>53</td>\n",
       "      <td>66</td>\n",
       "      <td>12.9</td>\n",
       "      <td>30</td>\n",
       "      <td>8735</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>417</td>\n",
       "      <td>349</td>\n",
       "      <td>137</td>\n",
       "      <td>60</td>\n",
       "      <td>89</td>\n",
       "      <td>510</td>\n",
       "      <td>63</td>\n",
       "      <td>12960</td>\n",
       "      <td>5450</td>\n",
       "      <td>450</td>\n",
       "      <td>875</td>\n",
       "      <td>92</td>\n",
       "      <td>97</td>\n",
       "      <td>7.7</td>\n",
       "      <td>37</td>\n",
       "      <td>19016</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>193</td>\n",
       "      <td>146</td>\n",
       "      <td>55</td>\n",
       "      <td>16</td>\n",
       "      <td>44</td>\n",
       "      <td>249</td>\n",
       "      <td>869</td>\n",
       "      <td>7560</td>\n",
       "      <td>4120</td>\n",
       "      <td>800</td>\n",
       "      <td>1500</td>\n",
       "      <td>76</td>\n",
       "      <td>72</td>\n",
       "      <td>11.9</td>\n",
       "      <td>2</td>\n",
       "      <td>10922</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Private  Apps  Accept  Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0     Yes  1660    1232     721         23         52         2885   \n",
       "1     Yes  2186    1924     512         16         29         2683   \n",
       "2     Yes  1428    1097     336         22         50         1036   \n",
       "3     Yes   417     349     137         60         89          510   \n",
       "4     Yes   193     146      55         16         44          249   \n",
       "\n",
       "   P.Undergrad  Outstate  Room.Board  Books  Personal  PhD  Terminal  \\\n",
       "0          537      7440        3300    450      2200   70        78   \n",
       "1         1227     12280        6450    750      1500   29        30   \n",
       "2           99     11250        3750    400      1165   53        66   \n",
       "3           63     12960        5450    450       875   92        97   \n",
       "4          869      7560        4120    800      1500   76        72   \n",
       "\n",
       "   S.F.Ratio  perc.alumni  Expend  Grad.Rate  \n",
       "0       18.1           12    7041         60  \n",
       "1       12.2           16   10527         56  \n",
       "2       12.9           30    8735         54  \n",
       "3        7.7           37   19016         59  \n",
       "4       11.9            2   10922         15  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('college.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385e8fd7",
   "metadata": {},
   "source": [
    "2. Use LabelEncoder to encode the target variable in to numerical form and split the data such that 20% of the data is set aside for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5648a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "df.Private = le.fit_transform(df.Private)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fa8f9d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df.iloc[:,1:]\n",
    "y=df.Private\n",
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, random_state=42, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f84ff",
   "metadata": {},
   "source": [
    "3. Fit a linear svm from scikit learn and observe the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4086a23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.8205128205128205\n",
      "The Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.58        47\n",
      "           1       0.80      1.00      0.89       109\n",
      "\n",
      "    accuracy                           0.82       156\n",
      "   macro avg       0.90      0.70      0.73       156\n",
      "weighted avg       0.86      0.82      0.79       156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\MachineLearning\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "model_svm = svm.LinearSVC()\n",
    "model_svm.fit(X_train,y_train)\n",
    "y_predict = model_svm.predict(X_test)\n",
    "print('The Accuracy is:', metrics.accuracy_score(y_test,y_predict))\n",
    "print('The Classification report:\\n', metrics.classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36ab01d",
   "metadata": {},
   "source": [
    "4. Preprocess the data using StandardScalar and fit the same model again and observe the change in accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c84d9d7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Apps</th>\n",
       "      <th>Accept</th>\n",
       "      <th>Enroll</th>\n",
       "      <th>Top10perc</th>\n",
       "      <th>Top25perc</th>\n",
       "      <th>F.Undergrad</th>\n",
       "      <th>P.Undergrad</th>\n",
       "      <th>Outstate</th>\n",
       "      <th>Room.Board</th>\n",
       "      <th>Books</th>\n",
       "      <th>Personal</th>\n",
       "      <th>PhD</th>\n",
       "      <th>Terminal</th>\n",
       "      <th>S.F.Ratio</th>\n",
       "      <th>perc.alumni</th>\n",
       "      <th>Expend</th>\n",
       "      <th>Grad.Rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.346882</td>\n",
       "      <td>-0.321205</td>\n",
       "      <td>-0.063509</td>\n",
       "      <td>-0.258583</td>\n",
       "      <td>-0.191827</td>\n",
       "      <td>-0.168116</td>\n",
       "      <td>-0.209207</td>\n",
       "      <td>-0.746356</td>\n",
       "      <td>-0.964905</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>1.270045</td>\n",
       "      <td>-0.163028</td>\n",
       "      <td>-0.115729</td>\n",
       "      <td>1.013776</td>\n",
       "      <td>-0.867574</td>\n",
       "      <td>-0.501910</td>\n",
       "      <td>-0.318252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.210884</td>\n",
       "      <td>-0.038703</td>\n",
       "      <td>-0.288584</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-1.353911</td>\n",
       "      <td>-0.209788</td>\n",
       "      <td>0.244307</td>\n",
       "      <td>0.457496</td>\n",
       "      <td>1.909208</td>\n",
       "      <td>1.215880</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>-2.675646</td>\n",
       "      <td>-3.378176</td>\n",
       "      <td>-0.477704</td>\n",
       "      <td>-0.544572</td>\n",
       "      <td>0.166110</td>\n",
       "      <td>-0.551262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.406866</td>\n",
       "      <td>-0.376318</td>\n",
       "      <td>-0.478121</td>\n",
       "      <td>-0.315307</td>\n",
       "      <td>-0.292878</td>\n",
       "      <td>-0.549565</td>\n",
       "      <td>-0.497090</td>\n",
       "      <td>0.201305</td>\n",
       "      <td>-0.554317</td>\n",
       "      <td>-0.905344</td>\n",
       "      <td>-0.259582</td>\n",
       "      <td>-1.204845</td>\n",
       "      <td>-0.931341</td>\n",
       "      <td>-0.300749</td>\n",
       "      <td>0.585935</td>\n",
       "      <td>-0.177290</td>\n",
       "      <td>-0.667767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.668261</td>\n",
       "      <td>-0.681682</td>\n",
       "      <td>-0.692427</td>\n",
       "      <td>1.840231</td>\n",
       "      <td>1.677612</td>\n",
       "      <td>-0.658079</td>\n",
       "      <td>-0.520752</td>\n",
       "      <td>0.626633</td>\n",
       "      <td>0.996791</td>\n",
       "      <td>-0.602312</td>\n",
       "      <td>-0.688173</td>\n",
       "      <td>1.185206</td>\n",
       "      <td>1.175657</td>\n",
       "      <td>-1.615274</td>\n",
       "      <td>1.151188</td>\n",
       "      <td>1.792851</td>\n",
       "      <td>-0.376504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.726176</td>\n",
       "      <td>-0.764555</td>\n",
       "      <td>-0.780735</td>\n",
       "      <td>-0.655656</td>\n",
       "      <td>-0.596031</td>\n",
       "      <td>-0.711924</td>\n",
       "      <td>0.009005</td>\n",
       "      <td>-0.716508</td>\n",
       "      <td>-0.216723</td>\n",
       "      <td>1.518912</td>\n",
       "      <td>0.235515</td>\n",
       "      <td>0.204672</td>\n",
       "      <td>-0.523535</td>\n",
       "      <td>-0.553542</td>\n",
       "      <td>-1.675079</td>\n",
       "      <td>0.241803</td>\n",
       "      <td>-2.939613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>-0.208040</td>\n",
       "      <td>-0.205673</td>\n",
       "      <td>-0.255200</td>\n",
       "      <td>-1.336352</td>\n",
       "      <td>-1.505488</td>\n",
       "      <td>-0.126030</td>\n",
       "      <td>0.771435</td>\n",
       "      <td>-0.906289</td>\n",
       "      <td>-0.417455</td>\n",
       "      <td>-0.299280</td>\n",
       "      <td>-0.207855</td>\n",
       "      <td>-0.775861</td>\n",
       "      <td>-1.339146</td>\n",
       "      <td>1.746877</td>\n",
       "      <td>-0.706073</td>\n",
       "      <td>-0.994781</td>\n",
       "      <td>-1.483301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>-0.269575</td>\n",
       "      <td>-0.087284</td>\n",
       "      <td>-0.091509</td>\n",
       "      <td>-0.201858</td>\n",
       "      <td>-0.444454</td>\n",
       "      <td>-0.175543</td>\n",
       "      <td>0.165435</td>\n",
       "      <td>0.268462</td>\n",
       "      <td>0.549707</td>\n",
       "      <td>0.306784</td>\n",
       "      <td>-0.133960</td>\n",
       "      <td>0.020822</td>\n",
       "      <td>-0.319632</td>\n",
       "      <td>-0.199632</td>\n",
       "      <td>0.666685</td>\n",
       "      <td>-0.090290</td>\n",
       "      <td>1.021555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>-0.233895</td>\n",
       "      <td>-0.042377</td>\n",
       "      <td>-0.091509</td>\n",
       "      <td>0.365389</td>\n",
       "      <td>0.262901</td>\n",
       "      <td>-0.187095</td>\n",
       "      <td>-0.453053</td>\n",
       "      <td>-0.880670</td>\n",
       "      <td>-0.143730</td>\n",
       "      <td>0.409815</td>\n",
       "      <td>-0.827095</td>\n",
       "      <td>-0.346878</td>\n",
       "      <td>-0.319632</td>\n",
       "      <td>0.078441</td>\n",
       "      <td>-0.221570</td>\n",
       "      <td>-0.256241</td>\n",
       "      <td>-0.959029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>775</th>\n",
       "      <td>1.991711</td>\n",
       "      <td>0.177256</td>\n",
       "      <td>0.578333</td>\n",
       "      <td>3.825595</td>\n",
       "      <td>2.182866</td>\n",
       "      <td>0.312977</td>\n",
       "      <td>-0.507606</td>\n",
       "      <td>2.337894</td>\n",
       "      <td>1.963953</td>\n",
       "      <td>0.488603</td>\n",
       "      <td>1.144424</td>\n",
       "      <td>1.430339</td>\n",
       "      <td>1.107689</td>\n",
       "      <td>-2.095582</td>\n",
       "      <td>2.120194</td>\n",
       "      <td>5.887971</td>\n",
       "      <td>1.953595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>776</th>\n",
       "      <td>-0.003268</td>\n",
       "      <td>-0.066872</td>\n",
       "      <td>-0.095816</td>\n",
       "      <td>0.025041</td>\n",
       "      <td>0.363952</td>\n",
       "      <td>-0.146867</td>\n",
       "      <td>0.572283</td>\n",
       "      <td>-1.355744</td>\n",
       "      <td>-0.727676</td>\n",
       "      <td>-0.299280</td>\n",
       "      <td>-0.133960</td>\n",
       "      <td>0.143389</td>\n",
       "      <td>-0.319632</td>\n",
       "      <td>1.013776</td>\n",
       "      <td>0.424434</td>\n",
       "      <td>-0.987116</td>\n",
       "      <td>1.953595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>777 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Apps    Accept    Enroll  Top10perc  Top25perc  F.Undergrad  \\\n",
       "0   -0.346882 -0.321205 -0.063509  -0.258583  -0.191827    -0.168116   \n",
       "1   -0.210884 -0.038703 -0.288584  -0.655656  -1.353911    -0.209788   \n",
       "2   -0.406866 -0.376318 -0.478121  -0.315307  -0.292878    -0.549565   \n",
       "3   -0.668261 -0.681682 -0.692427   1.840231   1.677612    -0.658079   \n",
       "4   -0.726176 -0.764555 -0.780735  -0.655656  -0.596031    -0.711924   \n",
       "..        ...       ...       ...        ...        ...          ...   \n",
       "772 -0.208040 -0.205673 -0.255200  -1.336352  -1.505488    -0.126030   \n",
       "773 -0.269575 -0.087284 -0.091509  -0.201858  -0.444454    -0.175543   \n",
       "774 -0.233895 -0.042377 -0.091509   0.365389   0.262901    -0.187095   \n",
       "775  1.991711  0.177256  0.578333   3.825595   2.182866     0.312977   \n",
       "776 -0.003268 -0.066872 -0.095816   0.025041   0.363952    -0.146867   \n",
       "\n",
       "     P.Undergrad  Outstate  Room.Board     Books  Personal       PhD  \\\n",
       "0      -0.209207 -0.746356   -0.964905 -0.602312  1.270045 -0.163028   \n",
       "1       0.244307  0.457496    1.909208  1.215880  0.235515 -2.675646   \n",
       "2      -0.497090  0.201305   -0.554317 -0.905344 -0.259582 -1.204845   \n",
       "3      -0.520752  0.626633    0.996791 -0.602312 -0.688173  1.185206   \n",
       "4       0.009005 -0.716508   -0.216723  1.518912  0.235515  0.204672   \n",
       "..           ...       ...         ...       ...       ...       ...   \n",
       "772     0.771435 -0.906289   -0.417455 -0.299280 -0.207855 -0.775861   \n",
       "773     0.165435  0.268462    0.549707  0.306784 -0.133960  0.020822   \n",
       "774    -0.453053 -0.880670   -0.143730  0.409815 -0.827095 -0.346878   \n",
       "775    -0.507606  2.337894    1.963953  0.488603  1.144424  1.430339   \n",
       "776     0.572283 -1.355744   -0.727676 -0.299280 -0.133960  0.143389   \n",
       "\n",
       "     Terminal  S.F.Ratio  perc.alumni    Expend  Grad.Rate  \n",
       "0   -0.115729   1.013776    -0.867574 -0.501910  -0.318252  \n",
       "1   -3.378176  -0.477704    -0.544572  0.166110  -0.551262  \n",
       "2   -0.931341  -0.300749     0.585935 -0.177290  -0.667767  \n",
       "3    1.175657  -1.615274     1.151188  1.792851  -0.376504  \n",
       "4   -0.523535  -0.553542    -1.675079  0.241803  -2.939613  \n",
       "..        ...        ...          ...       ...        ...  \n",
       "772 -1.339146   1.746877    -0.706073 -0.994781  -1.483301  \n",
       "773 -0.319632  -0.199632     0.666685 -0.090290   1.021555  \n",
       "774 -0.319632   0.078441    -0.221570 -0.256241  -0.959029  \n",
       "775  1.107689  -2.095582     2.120194  5.887971   1.953595  \n",
       "776 -0.319632   1.013776     0.424434 -0.987116   1.953595  \n",
       "\n",
       "[777 rows x 17 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sc= StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(df_sc, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6bf821ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Accuracy is: 0.9294871794871795\n",
      "The Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.89      0.88        47\n",
      "           1       0.95      0.94      0.95       109\n",
      "\n",
      "    accuracy                           0.93       156\n",
      "   macro avg       0.91      0.92      0.92       156\n",
      "weighted avg       0.93      0.93      0.93       156\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\MachineLearning\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:985: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\"Liblinear failed to converge, increase \"\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test  = train_test_split(X, y, random_state=42, test_size=0.20)\n",
    "model_svm = svm.LinearSVC()\n",
    "model_svm.fit(X_train,y_train)\n",
    "y_predict = model_svm.predict(X_test)\n",
    "print('The Accuracy is:', metrics.accuracy_score(y_test,y_predict))\n",
    "print('The Classification report:\\n', metrics.classification_report(y_test,y_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf1b5c0",
   "metadata": {},
   "source": [
    "5. Use scikit learn’s gridsearch to select the best hyperparameter for a non-linear SVM, identify the model with best score and its parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "86f2028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = [\n",
    "    {'C': [0.1, 1, 10, 100], 'kernel': ['poly','linear','rbf'], 'gamma': [0.001, 0.0001]}\n",
    "]\n",
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a69fc2ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "RandomSearch = RandomizedSearchCV(estimator=svm.SVC(max_iter=1000),\n",
    "                   param_distributions=parameters, n_jobs=-1, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7da6a8e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9441542925413892\n",
      "Best parameters: {'kernel': 'linear', 'gamma': 0.0001, 'C': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\MachineLearning\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=1000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    }
   ],
   "source": [
    "RandomSearch.fit(X_train,y_train)\n",
    "print('Best score:', RandomSearch.best_score_)\n",
    "print('Best parameters:', RandomSearch.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd75f3be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
