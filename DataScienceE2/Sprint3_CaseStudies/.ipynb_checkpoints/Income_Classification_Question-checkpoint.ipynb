{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d973b46a",
   "metadata": {},
   "source": [
    "## **Machine Learning Logisitic Regression  Challenge on Income Data Set**\n",
    "Welcome to the machine learning challnege, in this scenario, you will be exploring logistic regression on income dataset\n",
    "\n",
    "**Note** -\n",
    "- Write the solution in this notebook by adding cells and follow the given instructions below. (Add additional notebook for coding if necessary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9861a86",
   "metadata": {},
   "source": [
    "## Provided Dataset and Instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b6ca10",
   "metadata": {},
   "source": [
    "\n",
    " - The dataset provided here is income.csv has 43957 records with a target attribute as **income_>50K** containing values **1** and **0**.\n",
    " \n",
    " \n",
    " - Use this dataset to build the model by splitting the data into train and test split. (Here keep 80% of data as train dataset and remaining as test dataset)\n",
    " \n",
    " \n",
    "- The final score evaluation is based on Accuracy Score, Macro - F1 Score and Area Under the ROC Curve Score (ROC - AUC Score),Sensitivity ,Specificity and confusion matric on the test dataset.\n",
    "\n",
    "\n",
    "- **Hint** - Here try treating the null values and tuning the parameters of the model for better performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f27989",
   "metadata": {},
   "source": [
    "### Submission Details\n",
    "\n",
    "- Write the code to build the model and predicts the `income_>50K` (0 or 1) for the records in test dataset.\n",
    "\n",
    "\n",
    "\n",
    "- Once the predictions are ready kindly calculate the metrics accuracy, macro-f1 score, roc-auc score , sensitivity, specificity and confusion matrix and save it in the variables **income_acc**,**income_f1_macro** , **income_roc** , **income_sensitivity** ,**income_specificity** and **income_confusion**. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Note**\n",
    "\n",
    "- Here, run the first two cells to import the necessary packages and to download the datasets, and final two cells to save the results in the directory and to evaluate the results. \n",
    "\n",
    "\n",
    "\n",
    "- Here , this is the categorical codes for the target variable `income_>50K` -\n",
    "\n",
    " \n",
    "\n",
    "- no - 0,\n",
    "\n",
    "- yes - 1\n",
    "\n",
    "\n",
    "\n",
    "- Additional packages can be installed in the notebook using the command: \n",
    "\n",
    "\t\t !pip3 install --user package_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ef6d64",
   "metadata": {},
   "source": [
    "## Run the below cell to import the necessary packages required for the challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bc24f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d44428",
   "metadata": {},
   "source": [
    "## Run the below cell to download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05e88bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2021-09-14 12:09:18--  http://hrcdn.net/s3_pub/istreet-assets/jPlUtUXGWJSIuuj0QIpMNg/income.csv\n",
      "Resolving hrcdn.net (hrcdn.net)... 2600:140f:5::6011:c273, 2600:140f:5::6011:c252, 23.50.232.248, ...\n",
      "Connecting to hrcdn.net (hrcdn.net)|2600:140f:5::6011:c273|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://hrcdn.net/s3_pub/istreet-assets/jPlUtUXGWJSIuuj0QIpMNg/income.csv [following]\n",
      "--2021-09-14 12:09:18--  https://hrcdn.net/s3_pub/istreet-assets/jPlUtUXGWJSIuuj0QIpMNg/income.csv\n",
      "Connecting to hrcdn.net (hrcdn.net)|2600:140f:5::6011:c273|:443... connected.\n",
      "ERROR: cannot verify hrcdn.net's certificate, issued by 'CN=DigiCert SHA2 Secure Server CA,O=DigiCert Inc,C=US':\n",
      "  Unable to locally verify the issuer's authority.\n",
      "To connect to hrcdn.net insecurely, use `--no-check-certificate'.\n"
     ]
    }
   ],
   "source": [
    "!wget hrcdn.net/s3_pub/istreet-assets/jPlUtUXGWJSIuuj0QIpMNg/income.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb269d5a",
   "metadata": {},
   "source": [
    "### Follow the below steps for building the solution\n",
    "\n",
    "  - Read the dataset and have a look at the attributes of the dataset.\n",
    "  \n",
    "  \n",
    "  - Look for null values in the dataset and treat those null values with appropriate techniques.\n",
    "  \n",
    "  \n",
    "  - Convert the categorical columns to numerical column by label encoding those columns.\n",
    "  \n",
    "  \n",
    "  - Select the values for dependent and independent variables and split the dataset into train and test dataset. (Select 80% of data for training and remaining data as test dataset).\n",
    "  \n",
    "  \n",
    "  - Fit the logisitc regression model by fine tuning the hyperparameters of the model.\n",
    "  \n",
    "  \n",
    "  - Evaluate the results by calculating the above mentioned metrics and save it in the apporpiate variables as mentioned in the instructions.\n",
    "  \n",
    "  \n",
    "   - Run the final two cells to save and validate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3682fadd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43957, 15)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Write your code here and add more cells for coding\n",
    "\n",
    "\n",
    "df = pd.read_csv('income.csv')\n",
    "\n",
    "df.shape\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82d6b193",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                   0\n",
       "workclass          2498\n",
       "fnlwgt                0\n",
       "education             0\n",
       "educational-num       0\n",
       "marital-status        0\n",
       "occupation         2506\n",
       "relationship          0\n",
       "race                  0\n",
       "gender                0\n",
       "capital-gain          0\n",
       "capital-loss          0\n",
       "hours-per-week        0\n",
       "native-country      763\n",
       "income_>50K           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "914c37a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e639247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 0, 0, 0], dtype=object)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df.values[:,14]\n",
    "df = df.drop('income_>50K', axis=1)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64d13eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 =df,\n",
    "def age_grp(x):\n",
    "    if (x<=25):\n",
    "        return('Young')\n",
    "    elif(x>25 and x<=60): \n",
    "        return('Middle Age')\n",
    "    else:\n",
    "        return('Senior')\n",
    "\n",
    "def workclass(x):\n",
    "    if (x == 'Private'):\n",
    "        return('Private')\n",
    "    else:\n",
    "        return('Others')\n",
    "    \n",
    "def edu_grp(x):\n",
    "    if (x=='12th' or x=='11th' or x=='10th' or x=='12th' or x=='1st-4th' or x=='5th-6th' or x=='7th-8th' or x=='9th' or x=='Preschool'): \n",
    "        return('LessEducated')\n",
    "    elif(x== 'Doctorate' or x == 'Prof-school' or x == 'Masters'): \n",
    "        return('HighlyEducated')\n",
    "    else:\n",
    "        return('Educated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a322dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "    df1=df\n",
    "    df1['Age_Group'] = df['age'].apply(lambda x:age_grp(x))\n",
    "    df1['workclass1'] = df1['workclass'].apply(lambda x:workclass(x))\n",
    "    df['education_category'] = df['education'].apply(lambda x:edu_grp(x))\n",
    "    df1= pd.get_dummies (df1, columns =['Age_Group'], drop_first=True)\n",
    "    df1 = pd.get_dummies (df1, columns =['gender'], drop_first=True)\n",
    "    df1 = pd.get_dummies(df1, columns =['workclass1'], drop_first=True)\n",
    "    df1 = pd.get_dummies(df1, columns =['education_category'], drop_first=True)\n",
    "    df1 = pd.get_dummies(df1, columns=['occupation'], drop_first=True)\n",
    "    df['education_category'] = df['education'].apply(lambda x:edu_grp(x))\n",
    "    #df1['workclass].value_counts 0,\n",
    "    df1= pd.get_dummies (df1, columns =['marital-status'], drop_first=True)\n",
    "    df1= pd.get_dummies (df1, columns =['race'], drop_first=True)\n",
    "    df1=df1.drop(['relationship', 'native-country', 'age', 'fnlwgt', 'workclass', 'education'], axis=1)\n",
    "    print(df1.columns)\n",
    "    x=df1.values[:,:]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "22e47766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['educational-num', 'capital-gain', 'capital-loss', 'hours-per-week',\n",
      "       'Age_Group_Senior', 'Age_Group_Young', 'gender_Male',\n",
      "       'workclass1_Private', 'education_category_HighlyEducated',\n",
      "       'education_category_LessEducated', 'occupation_Armed-Forces',\n",
      "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
      "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
      "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
      "       'occupation_Priv-house-serv', 'occupation_Prof-specialty',\n",
      "       'occupation_Protective-serv', 'occupation_Sales',\n",
      "       'occupation_Tech-support', 'occupation_Transport-moving',\n",
      "       'marital-status_Married-AF-spouse', 'marital-status_Married-civ-spouse',\n",
      "       'marital-status_Married-spouse-absent', 'marital-status_Never-married',\n",
      "       'marital-status_Separated', 'marital-status_Widowed',\n",
      "       'race_Asian-Pac-Islander', 'race_Black', 'race_Other', 'race_White'],\n",
      "      dtype='object')\n",
      "(40727, 33)\n"
     ]
    }
   ],
   "source": [
    "x=preprocessing(df)\n",
    "print(x.shape) \n",
    "y = y.reshape(-1, 1)\n",
    "y=y.astype('int') \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9cc7cf7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[    7     0     0 ...     0     0     1]\n",
      " [    6     0     0 ...     0     0     1]\n",
      " [   13     0     0 ...     0     0     1]\n",
      " ...\n",
      " [   12     0     0 ...     0     0     1]\n",
      " [   10 99999     0 ...     0     0     1]\n",
      " [    9     0     0 ...     0     0     1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test= train_test_split(x, y, test_size=0.20, random_state=42)\n",
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5818e42c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Sudip\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "log_reg = LogisticRegression().fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "model = LogisticRegression()\n",
    "solvers = ['newton-cg', 'lbfgs', 'liblinear']\n",
    "penalty = ['l2']\n",
    "c_values = [100, 10, 1.0, 0.1, 0.01]\n",
    "# define grid search\n",
    "grid = dict(solver=solvers,penalty=penalty,C=c_values)\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\n",
    "grid_result = grid_search.fit(X_train,y_train)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459707b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8a16061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6f68a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "income_acc = accuracy_score(y_test,y_predict)\n",
    "income_f1_macro = f1_score(y_test,y_predict,average='macro')\n",
    "income_roc=roc_auc_score(y_test,y_predict,average='macro')\n",
    "income_confusion=confusion_matrix(y_test,y_predict)\n",
    "total1=sum(sum(income_confusion))\n",
    "income_sensitivity=income_confusion[0,0]/(income_confusion[0,0]+income_confusion[0,1])\n",
    "income_specificity=income_confusion[1,1]/(income_confusion[1,0]+income_confusion[1,1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b4d4b0d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8363614043702431\n",
      "F1 Macro: 0.7634277039237677\n",
      "ROC: 0.7466239269997086\n",
      "Confusion Matrix: [[5668  467]\n",
      " [ 866 1145]]\n",
      "Sensitivity: 0.9238793806030969\n",
      "Specificity: 0.5693684733963202\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([5668,  467])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Accuracy:',income_acc)\n",
    "print('F1 Macro:',income_f1_macro)\n",
    "print('ROC:',income_roc)\n",
    "print('Confusion Matrix:',income_confusion)\n",
    "print('Sensitivity:',income_sensitivity)\n",
    "print('Specificity:',income_specificity)\n",
    "income_confusion[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f788971d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d1c90627",
   "metadata": {},
   "source": [
    "## Run the below cell to save your results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ddca2d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open(\"Confusion_Matrix.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_confusion, fp)\n",
    "    \n",
    "with open(\"Accuracy.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_acc, fp)\n",
    "    \n",
    "    \n",
    "with open(\"F1-Score-Macro.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_f1_macro, fp)\n",
    "    \n",
    "    \n",
    "with open(\"ROC-Score.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_roc, fp)\n",
    "    \n",
    "    \n",
    "with open(\"Sensitivity.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_sensitivity, fp)\n",
    "    \n",
    "    \n",
    "with open(\"Specificity.txt\", \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(income_specificity, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4fdcae2",
   "metadata": {},
   "source": [
    "## Run the below cell to validate the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "edfaa1fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Validations does not match the expected output\n"
     ]
    }
   ],
   "source": [
    "!python3 test.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aff3a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
